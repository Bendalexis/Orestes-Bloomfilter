{"name":"Orestes Bloom Filter Libarary","tagline":"Library of different Bloom filters for Java with Redis-backing, counting and many hashing options.","body":"Orestes Bloom filter library\r\n===================\r\n\r\nThis is a set of Bloom filters we implemented as we found all existing open-source implementations to be lacking in various aspects. This libary takes some inspiration from the [simple Bloom filter implementation of Magnus Skjegstad](https://github.com/MagnusS/Java-BloomFilter) and the [Ruby Bloom filters by Ilya Grigorik](https://github.com/igrigorik/bloomfilter-rb).\r\n\r\nThe Bloom filter is a probabilistic set data structure which is very small. This is achieved by allowing false positives with some probability *p*. It has an `add` and `contains` operation which both are very fast (time complexity *O(1)*). The Counting Bloom filter is an extension of the Bloom filter with a `remove` operation at the cost of incurring an additional space overhead for counting. There are many good introductions to Bloom filters: the [Wikipedia article](http://en.wikipedia.org/wiki/Bloom_filter) is excellent, and even better is a [survey by Broder and Mitzenmacher](http://www.cs.utexas.edu/~yzhang/teaching/cs386m-f8/Readings/im2005b.pdf). Typical use cases of Bloom filters are content summaries and sets that would usually grow too large in fields such as networking, distributed systems, databases and analytics.\r\n\r\nThere are 4 types of Bloom filters in the Orestes Bloom filter library:\r\n* **Regular Bloom filter**, a regular in-memory Java Bloom filter (`BloomFilter`)\r\n* **Counting Bloom filter**, a Counting Bloom Filter which supports element removal (`CBloomFilter`)\r\n* **Redis Bloom Filter**, a Redis-backed Bloom filter which can be concurrently used by different applications (`BloomFilterRedis`)\r\n* **Redis Counting Bloom Filter**, a Redis-backed, concurrency-safe Counting Bloom filter in two variants: one that holds a pregenerated regular Bloom filter and relies on Redis Lua scripting (`CBloomFilterRedisBits`) and one that can be distributed through client side consistent hasing or Redis Cluster (`CBloomFilterRedis`)\r\n\r\n### Docs\r\nThe Javadocs are online [here](http://orestes-bloomfilter-docs.s3-website-eu-west-1.amazonaws.com/) and in the */docs* folder of the repository.\r\n\r\n## Err, Bloom what?\r\nBloom filters are awesome data structures: **fast *and* maximally space efficient**.\r\n```java\r\nBloomFilter<String> urls = new BloomFilter<>(100_000_000, 0.01); //Expect 100M URLs\r\nurls.add(\"http://github.com\") //Add millions of URLs\r\nurls.contains(\"http://twitter.com\") //Know in an instant which ones you have or have not seen before\r\n```\r\nSo what's the catch? Bloom filters allow false positive (i.e. URL contained though never added) with some  probability (0.01 in the example). If you can mitigate rare \r\n\r\nfalse positives (false negatives never happen) then Bloom filters are probably for you.\r\n\r\n## Features\r\nThere are a many things we addressed as we sorely missed them in other implementations:\r\n* Bloom filter and Counting Bloom filter in both a local and shared variants with the same interface\r\n* Configuration of all parameters: Bit-Array size *m*, number of hash functions *k*, counting bits *c*\r\n* Automatic configuration given the tolerable false positive rate *p* and expected elements *n*\r\n* Statistics, e.g. what is my current false positive probability?\r\n* Choice among different hash functions: the better (i.e. uniformly distributed) the hash function, the more accurate the Bloom filter but the better the hash function usually the slower it is -> choose from about 10-15  optimized hash functions, e.g. MD5, SHA, Murmur, LCGs, Carter-Wegman etc. or use a custom one\r\n* Operations on the shared Bloom filter need to be fast (single round-trips to Redis per operation and heavy use of pipelining)\r\n* Generation of the Bloom filter is always fast (on-the-fly pregeneration)\r\n* Support of union and intersection\r\n* Implementation of [rejection sampling](http://en.wikipedia.org/wiki/Rejection_sampling) and chaining of hash values taking into account the [avalanche effect](http://en.wikipedia.org/wiki/Avalanche_effect) (higher hash quality)\r\n* Minimal dependencies: the local Bloom filters have none, the Redis Bloom filters need the [jedis](https://github.com/xetorthio/jedis) client library (in  `lib` folder)\r\n* Concurrency: the shared Bloom filter can be accessed by many clients simultaneously without multi-user anomalies and performance degradation (which is quite difficult for bitwise counters and a pregnerated Bloom filter - but possible)\r\n\r\n## Getting started\r\nDownload the [orestes-bf.jar](https://orestes-binaries.s3.amazonaws.com/orestes-bf.jar) and add it your classpath. The jar is also contained in the */build* folder of the repository. Or checkout the repository and build it using ant: `ant build`. For the normal Bloom filters it's even sufficient to only copy the source *.java files to your  project.\r\n\r\n## Usage\r\n- [Regular Bloom Filter](#a1)\r\n- [Counting Bloom Filter](#a2)\r\n- [Redis Bloom Filters](#a3)\r\n- [Redis Counting Bloom Filters](#a4)\r\n- [JSON Representation](#a5)\r\n- [Hash Functions](#a6)\r\n- [Performance](#a7)\r\n\r\n<a name=\"a1\"/>\r\n### Regular Bloom Filter\r\nThe regular Bloom filter is very easy to use. It is the base class of all other Bloom filters. Figure out how many elements you expect to have in the Bloom filter ( *n* ) and then which false positive rate is tolerable ( *p* ).\r\n\r\n```java\r\n//Create a Bloom filter that has a false positive rate of 0.1 when containing 1000 elements\r\nBloomFilter<String> bf = new BloomFilter<>(1000, 0.1);\r\n```\r\nThe Bloom filter class is generic and will work with any type that implements the `toString()` method in a sensible way, since that String is what the Bloom filter feeds into its hash functions. The `hashCode()` method is not used, since it returns integers that normally do not satisfy a uniform distribution of outputs that is essential for the optimal peformance of the Bloom filter. Now lets add something:\r\n\r\n```java\r\n//Add a few elements\r\nbf.add(\"Just\");\r\nbf.add(\"a\");\r\nbf.add(\"test.\");\r\n```\r\n\r\nAn element which was inserted in a Bloom filter will always be returned as being contained (no false negatives):\r\n\r\n```java\r\n//Test if they are contained\r\nprint(bf.contains(\"Just\")); //true\r\nprint(bf.contains(\"a\")); //true\r\nprint(bf.contains(\"test.\")); //true\r\n```\r\n\r\nUsually non-inserted elements will not be contained:\r\n```java\r\n//Test with a non-existing element\r\nprint(bf.contains(\"WingDangDoodel\")); //false\r\n```\r\nIf we add enough elements, false positives will start occurring:\r\n```java\r\n//Add 300 elements\r\nfor (int i = 0; i < 300; i++) {\r\n\tString element = \"Element \" + i;\r\n\tbf.add(element);\r\n}\t\r\n//test for false positives\r\nfor (int i = 300; i < 1000; i++) {\r\n\tString element = \"Element \" + i;\r\n\tif(bf.contains(element)) {\r\n\t\tprint(element); //two elements: 440, 669\r\n\t}\r\n}\r\n```\r\nLet's compare this with the expected amount of false positives:\r\n```java\r\n//Compare with the expected amount\r\nprint(bf.getFalsePositiveProbability(303) * 700); //1.74\r\n```\r\nSo our two false positives are in line with the expected amount of 1.74.\r\n\r\nThe Bloom filter can be cleared and cloned:\r\n```java\r\n//Clone the Bloom filter\r\nbf.clone();\r\n//Reset it, i.e. delete all elements\r\nbf.clear();\r\n```\r\n\r\nAlso elements can be added and queried in bulk:\r\n```java\r\nList<String> bulk = Arrays.asList(new String[] { \"one\", \"two\", \"three\" });\r\nbf.addAll(bulk);\r\nprint(bf.containsAll(bulk)); //true\r\n```\r\n\r\nTo get the best performance for a given use-case the parameters of the bloom filter must be chosen wisely. There are several helpers and constructor overloads to configure the Bloom filter. So for example we could choose the Bloom filter to use 1000 Bits and then use the best number of hash functions for an expected amount of 6666 inserted elements. We choose Murmur as our hash function which is faster than cryptographic hash functions like MD5:\r\n```java\r\n//Create a more customized Bloom filter\r\nint m = 10000; //Bits to use\r\nint k = BloomFilter.optimalK(6666, m); //Optimal number of hash functions given n and m\r\nHashMethod hash = HashMethod.Murmur; //The hash function type\r\nBloomFilter<Integer> bf2 = new BloomFilter<>(m, k);\r\n//Only set the hash function before using the Bloom filter\r\nbf2.setHashMethod(hash);\r\n```\r\n\r\nBloom filters allow other cool stuff too. Consider for instance that you collected two Bloom filters which are compatible in their parameters. Now you want to consolidate their elements. This is achieved by ORing the respective Bit-Arrays of the Bloom filters:\r\n```java\r\n//Create two Bloom filters with equal parameters\r\nBloomFilter<String> one = new BloomFilter<String>(100, 0.01);\r\nBloomFilter<String> other = new BloomFilter<String>(100, 0.01);\r\none.add(\"this\");\r\nother.add(\"that\");\r\none.union(other);\r\nprint(one.contains(\"this\")); //true\r\nprint(one.contains(\"that\")); //true\r\n```\r\n\r\nThe good thing about the `union()` operation is, that it returns the exact Bloom filter which would have been created, if all elements were inserted in one Bloom filter. There is a similar `intersect` operation that ANDs the Bit-Arrays. It does however behave slightly different as it does not return the Bloom filter that only contains the \r\nintersection. It guarantees to have all elements of the intersection but the false positive rate might be slightly higher than that of the pure intersection:\r\n\r\n```java\r\nother.add(\"this\");\r\nother.add(\"boggles\");\r\none.intersect(other);\r\nprint(one.contains(\"this\")); //true\r\nprint(one.contains(\"boggles\")); //false\r\n```\r\n\r\n<a name=\"a2\"/>\r\n## Counting Bloom Filter\r\nThe Counting Bloom filter allows object removal. For this purpose it has binary counters instead of simple bits. In `CBloomFilter` the amount of bits *c* per counter can be set. If you expect to insert elements only once, the probability of a Bit overflow is very small for *c = 4* : *1.37 * 10^-15 * m* for up to *n* inserted elements  ([details](http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html#SECTION00053000000000000000)). For most use-cases 4 Bits are the best choice.\r\n\r\n```java\r\n//Create a Counting Bloom filter that has a FP rate of 0.01 when 1000 are inserted\r\n//and uses 4 Bits for Counting\r\nCBloomFilter<String> cbf = new CBloomFilter<>(1000, 0.01, 4);\r\ncbf.add(\"http://google.com\");\r\ncbf.add(\"http://twitter.com\");\r\nprint(cbf.contains(\"http://google.com\")); //true\r\nprint(cbf.contains(\"http://twitter.com\")); //true\r\n```\r\n\r\nIf you insert one distinct item multiple times, the same counter always get updated so you should pick a higher *c* so that *2^c > inserted_copies*. The Counting Bloom Filter extends the normal Bloom Filter by `remove` and `removeAll` methods:\r\n\r\n```java\r\ncbf.remove(\"http://google.com\");\r\nprint(cbf.contains(\"http://google.com\")); //false\r\n```\r\n\r\nTo handle overflows (which is unlikely to ever be an issue) you can set an overflow callback:\r\n\r\n```java\r\n//Handling Overflows\r\ncbf.setOverflowHandler(new OverflowHandler() {\r\n\t@Override\r\n\tpublic void onOverflow() {\r\n\t\tprint(\"Oops, c should better be higher the next time.\");\r\n\t}\r\n});\r\nfor (int i = 1; i < 20; i++) {\r\n\tprint(\"Round \" + i);\r\n\tcbf.add(\"http://example.com\"); //Causes onOverflow() in Round >= 16\r\n}\r\n```\r\n\r\nTo understand the inner workings of the Counting Bloom filter lets actually look at the bits of small filter:\r\n\r\n```java\r\nCBloomFilter<String> small = new CBloomFilter<>(3, 0.2, 4);\r\nsmall.add(\"One\"); small.add(\"Two\"); small.add(\"Three\");\r\nprint(small.toString());\r\n```\r\nThis gives:\r\n```bash\r\nCounting Bloom Filter, Parameters m = 11, k = 3, c = 4\r\n1 0001\r\n0 0000\r\n1 0001\r\n0 0000\r\n0 0000\r\n0 0000\r\n1 0001\r\n0 0000\r\n1 0001\r\n0 0000\r\n1 0101\r\n```\r\n\r\nThe Counting Bloom filter thus has a bit size of 11, uses 3 hash functions and 4 bits for counting. The first row is the materialized bit array of all counters > 0. Explcitly saving it makes `contains` calls fast and generation when transferring the Counting Bloom Filter flattened to a Bloom filter.\r\n\r\n\r\n<a name=\"a3\"/>\r\n## Redis Bloom Filters\r\nBloom filters are really intresting beauce they allow very high throughput and minimal latency for adding and querying (and removing). Therefore you might want to use them across the boundaries of a single machine. For instance imagine you run a large scale web site or web service. You have a load balancer distributing the request load over several front-end web servers. You now want to store some information with a natural set structure, say, you want to know if a source IP adress has accessed the requested URL in the past. You could achieve that by either eplicitly storing that information (probably in a database) which will soon be a bottleneck if you serve billions of requests a day. Or you employ a shared Bloom filter and accept a small possibility of false positives.\r\n\r\nThese kind of use-cases are ideal for the Redis-backed Bloom filters of this library. They have the same Java Interfaces as the normal and Counting Bloom filter but store the Bloom filter bits in the [in-memory key-value store Redis](http://redis.io).\r\n\r\nReasons to use these Redis-backed Bloom filters instead of their pure Java brothers are:\r\n* **Concurrent** or **Distributed** Access to on Bloom filter\r\n* **Persistence** Requirements (e.g. saving the Bloom filter to disk once every second)\r\n* **Scalability** of the Bloom Filter beyond one machine ([Redis Cluster](http://redis.io/topics/cluster-spec) or client-side sharding with *CBlommFilterRedisSharded* which is under development )\r\n\r\nUsing the Redis-backed Bloom filter is straightforward:\r\n\r\n1. Install Redis. This is extremely easy: [see Redis Installation](http://redis.io/download).\r\n2. Start Redis with `$ redis-server`. The server will listen on port 6379.\r\n3. In your application (might be on a different machine) instantiate a Redis-backed Bloom filter giving the IP or host name of Redis and its port: `new BloomFilterRedis<>(\"192.168.44.131\", 6379, 10000, 0.01);`\r\n\r\nThe Redis-backed Bloom filters have the same Interface as the normal Bloom filters:\r\n\r\n```java\r\n//Redis' IP\r\nString IP = \"192.168.44.131\";\t\r\n//Open a Redis-backed Bloom filter\r\nBloomFilterRedis<String> bfr = new BloomFilterRedis<>(IP, 6379, 10000, 0.01);\r\nbfr.add(\"cow\");\r\n\r\n//Open a second Redis-backed Bloom filter with a new connection\r\nBloomFilterRedis<String> bfr2 = new BloomFilterRedis<>(IP, 6379, 10000, 0.01);\r\nbfr2.add(\"bison\");\r\n\r\nprint(bfr.contains(\"cow\")); //true\r\nprint(bfr.contains(\"bison\")); //true\r\n```\r\n\r\nThe Redis-backed Bloom filters are concurrency/thread-safe at the backend. That means you can concurrently insert from any machine without running into anomalies, inconsistencies or lost data. The Redis-backed Bloom filters are implemented using efficient [Redis bit arrays](http://redis.io/commands/getbit). They make heavy use of [pipelining](http://redis.io/topics/pipelining) so that every `add` and `contains` call only needs one round-trip. This is the most performance critical aspect and usually not found in [other implementations](https://github.com/igrigorik/bloomfilter-rb) which need one round-trip for every Bit or worse.\r\n\r\nThe Redis-backed Bloom filters save their metadata (like number and kind of hash functions) in Redis, too. Thus other clients can easily to connect to a Redis instance that already holds a Bloom filter using `new BloomFilterRedis(new Jedis(ip, port))` or the similar constructors of *CBloomFilterRedis* or *CBloomFilterRedisBits*.\r\n\r\n<a name=\"a4\"/>\r\n## Redis Counting Bloom Filters\r\nThere are two kinds of Redis-backed Counting Bloom filters:\r\n* **CBloomfilterRedis** saves the counters as separate keys and keeps the materialized flat Bloom filter as bit array. It is comptatible with Redis 2.4 or higher.\r\n* **CBloomFilterRedisBits** uses a bit array for the counters. This is much more space efficient (~ factor 10) but needs at least Redis 2.6 as it relies on Lua scripting.\r\n\r\n```java\r\nCBloomFilterRedis<String> cbfr = new CBloomFilterRedis<>(IP, 6379, 10000, 0.01);\r\ncbfr.add(\"cow\");\r\nCBloomFilterRedis<String> bfr2 = new CBloomFilterRedis<>(IP, 6379, 10000, 0.01);\r\nbfr2.add(\"bison\");\r\nbfr2.remove(\"cow\");\r\nprint(cbfr.contains(\"bison\")); //true\r\nprint(cbfr.contains(\"cow\")); //false\r\n```\r\n\r\n*CBloomFilterRedisBits* works similar but you have to provide the counter size *c*. It uses Lua scripts (stored procedures in Redis) to atomically increment and decrement on a bit array. If you use Redis 2.6 or higher and it runs on one machine, you should choose *CBloomFilterRedisBits* as it consumes much less memory.\r\n\r\n<a name=\"a5\"/>\r\n## JSON Representation\r\nTo easily transfer a Bloom filter to a client (for instance via an HTTP GET) there is a JSON Converter for the Bloom filters are implemented so that this generation option is very cheap (i.e. just sequntially reading it from memory). It works for all Bloom filters including the ones backed by Redis.\r\n```java\r\nBloomFilter<String> bf = new BloomFilter<>(50, 0.1);\r\nbf.add(\"Ululu\");\r\nJsonElement json = BloomFilterConverter.toJson(bf);\r\nprint(json); //{\"m\":240,\"k\":4,\"HashMethod\":\"Cryptographic\",\"CryptographicHashFunction\":\"MD5\",\"bits\":\"AAAAEAAAAACAgAAAAAAAAAAAAAAQ\"}\r\nBloomFilter<String> otherBf = BloomFilterConverter.fromJson(json);\r\nprint(bf.contains(\"Ululu\")); //true\r\n```\r\nJSON is not an ideal format for binary content (Base64 only uses 64 out of 94 possible characters) it's highly interoperable and easy to read which outweighs the slight waste of space. Combining it with a [Content-Encoding](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html) like gzip usually compensates that.\r\n\r\n<a name=\"a6\"/>\r\n## Hash Functions\r\nThere is a detailed description of the available hash functions in the <a href=\"http://orestes-bloomfilter-docs.s3-website-eu-west-1.amazonaws.com/orestes/bloomfilter/BloomFilter.html#setHashMethod(orestes.bloomfilter.BloomFilter.HashMethod)\">Javadocs of the Bloomfilter.setHashMethod method</a> and the Javadocs of the respective hash function implementations. Hash uniformity (i.e. all bits of the Bloom filter are equally likely) is of great importance for the false positive rate. But there is also an inherent tradeoff between hash uniformity and speed of computation. For instance cryptographic hash functions have very good distribution properties but are very CPU intensive. Pseudorandom number generators like the [linear congruential generator](http://en.wikipedia.org/wiki/Linear_congruential_generator) are easy to compute but do not have perfectly random outputs but rather certain distribution patterns which for some inputs are notable and for others are negligible. The implementations of all hash functions are part of the BloomFilter class and use tricks like [rejection sampling](https://en.wikipedia.org/wiki/Rejection_sampling) to get the best possible distribution for the respective hash function type.\r\n\r\nHere is a Box plot overview of how good the different hash functions perform (Intel i7 w/ 4 cores, 8 GB RAM). The configuration is 1000000 hashes using k = 5, m = 1000 averaged over 10 runs. \r\n\r\n<img src=\"https://orestes-bloomfilter-images.s3-external-3.amazonaws.com/hash-speed.png\"/>\r\n\r\nSpeed of computation doesn't tell much about the quality of hash values. A good hash function is one, which has a discrete uniform distribution of outputs. That means that every bit of the Bloom filter's bit vector is equally likely to bet set. To measure if and how good the hash functions follow a uniform distribution [goodness of fit Chi-Square hypothesis tests](http://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test) are the mathematical instrument of choice.\r\n\r\nHere are some of the results. The inputs are random strings. The p-value is the probability of getting a statistical result that is at least as extreme as the obtained result. So the usual way of hypothesis testing would be rejecting the null hypothesis (\"the hash hash function is uniformly distributed\") if the p-value is smaller than 0.05. We did 100 Chi-Square Tests:\r\n\r\n<img src=\"https://orestes-bloomfilter-images.s3-external-3.amazonaws.com/chi-strings.png\"/>\r\n\r\nIf about 5 runs fail the test an 95 pass it, we can be very confident that the hash function is indeed uniformly distributed. For random inputs it is relatively easy though, so we also tested other input distribution, e.g. increasing integers:\r\n\r\n<img src=\"https://orestes-bloomfilter-images.s3-external-3.amazonaws.com/chi-ints.png\"/>\r\n\r\nHere the LCG is too evenly distributed (due to its modulo arithmetics) which is a good thing here, but shows, that LCGs do not have a random uniform distribution. The Carter-Wegman hash function fails because its constants are too small.\r\n\r\nNow a real example of inserting random elements in the Bloom filter, ordered by the false postive rate after  n = 30000 inserted elements using m = 300000 bits:\r\n\r\n<table>\r\n<tr><th>Hashfunction</th><th>Speed  (ms)</th><th>f during insert</th><th>f final</th></tr>\r\n <tr><td>SimpleLCG</td><td>26,83</td><td>0,0016</td><td>0,0095</td></tr>\r\n <tr><td>Cryptographic (MD5)</td><td>247,8</td><td>0,0017</td><td>0,0097</td></tr>\r\n <tr><td>Java RNG</td><td>37,05</td><td>0,0013</td><td>0,0101</td></tr>\r\n <tr><td>SecureRNG</td><td>263,2</td><td>0,0013</td><td>0,0101</td></tr>\r\n <tr><td>CarterWegman</td><td>606,76</td><td>0,0013</td><td>0,0101</td></tr>\r\n <tr><td>CRC32</td><td>114,4</td><td>0,0012</td><td>0,0102</td></tr>\r\n <tr><td>Cryptographic (SHA-256)</td><td>265,28</td><td>0,0012</td><td>0,0103</td></tr>\r\n <tr><td>Murmur</td><td>57,94</td><td>0,0017</td><td>0,0104</td></tr>\r\n <tr><td>Cryptographic (SHA1)</td><td>257,99</td><td>0,0016</td><td>0,0105</td></tr>\r\n <tr><td>Cryptographic (SHA-512)</td><td>232,22</td><td>0,0015</td><td>0,0111</td></tr>\r\n <tr><td>Adler32</td><td>116,73</td><td>0,9282</td><td>0,986</td></tr>\r\n</table>\r\n\r\nIn summary, cryptographic hash functions offer the most consistent uniform distribution, but are slightly more expensive to compute. LCGs, for instance Java Random, perform quite well in most cases and are cheap to compute. The best compromise seems to be the [Murmur hash function](https://sites.google.com/site/murmurhash/), which has a good distribution and is quite fast to compute.\r\n\r\nIt's also possible to provide a custom hash function:\r\n```java\r\nBloomFilter<String> bf = new BloomFilter<>(1000, 0.01);\r\nbf.setCusomHashFunction(new CustomHashFunction() {\r\n\t@Override\r\n\tpublic int[] hash(byte[] value, int m, int k) {\r\n\t\t//...\r\n\t}\t\t\t\r\n});\r\n```\r\n\r\n\r\n<a name=\"a7\"/>\r\n## Performance\r\nTo get meaningful results, the Bloom filters should be tested on a machine where there are to be run. The test package contains a benchmark procedure (the test packages relies on the Apache Commons Math library):\r\n\r\n```java\r\nBloomFilter<String> bf = new BloomFilter<>(100_000, 0.01);\r\nBFTests.benchmark(bf, \"My test\", 1_000_000);\r\n```\r\nThis gives over 500000 operations per second (on my machine):\r\n```\r\nMy test\r\nk = 7 p = 0.9952950593251605 n = 1000000 m = 958506\r\nadd(): 1.943s, 514668.0391 elements/s\r\naddAll(): 1.59s, 628930.8176 elements/s\r\ncontains(), existing: 1.429s, 699790.063 elements/s\r\ncontains(), nonexisting: 1.469s, 680735.194 elements/s\r\n100000 hash() calls: 0.029s, 3448275.8621 elements/s\r\nHash Quality (Chi-Squared-Test): p-value = 0.9487628088638604 , Chi-Squared-Statistic = 956245.1584854313\r\n```\r\n\r\nThe Redis-backed and Counting Bloom filters can also be tested.\r\n\r\n\r\nNext steps\r\n==========\r\n- Compatible Javascript implementation which can consume the JSON Bloom filter representation\r\n- *CBloomFilterSharded* which just uses counters as keys without a materialized bit array. It will have no hotspots and use client-side sharding to distribute keys over an arbitrary amount of Redis instances. The trade-off is unlimited horizontal scalability vs inefficient generation of the flat Bloom filter.\r\n\r\nOther Bloom filter libraries\r\n============================\r\n\r\n\r\nLicense\r\n=======\r\nThis Bloom filter library is published under the very permissive MIT license:\r\n\r\nCopyright Felix Gessert and Florian Bücklers. All rights reserved.\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to\r\ndeal in the Software without restriction, including without limitation the\r\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\r\nsell copies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in\r\nall copies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\r\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\r\nIN THE SOFTWARE.\r\n","google":"UA-39113218-1","note":"Don't delete this file! It's used internally to help with page regeneration."}